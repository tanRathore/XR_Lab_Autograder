{
   "cells": [
    {
     "cell_type": "code",
     "execution_count": 6,
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "text": [
        "ğŸ”§ Converting vidyalatanvi_LATE_218146_14937211_COGS 160 A1-1.docx â†’ vidyalatanvi_LATE_218146_14937211_COGS 160 A1-1.pdf â€¦\n"
       ]
      },
      {
       "name": "stderr",
       "output_type": "stream",
       "text": [
        "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]\n"
       ]
      },
      {
       "name": "stdout",
       "output_type": "stream",
       "text": [
        "\n",
        "ğŸ“„ Extracting images from mainayardaniel_127050_14924649_COGS 160 Le Corbusier Doc.pdf (56 pages)â€¦\n"
       ]
      }
     ],
     "source": [
      "import os\n",
      "import fitz       # PyMuPDF\n",
      "import pandas as pd\n",
      "from PIL import Image\n",
      "from io import BytesIO\n",
      "from tqdm import tqdm\n",
      "from docx2pdf import convert\n",
      "\n",
      "def preprocess_docs(input_dir: str):\n",
      "    \"\"\"\n",
      "    Convert all .docx/.doc files in input_dir into PDFs\n",
      "    with the same base filename.\n",
      "    \"\"\"\n",
      "    for filename in os.listdir(input_dir):\n",
      "        lower = filename.lower()\n",
      "        if lower.endswith((\".docx\", \".doc\")):\n",
      "            doc_path = os.path.join(input_dir, filename)\n",
      "            pdf_path = os.path.join(\n",
      "                input_dir,\n",
      "                os.path.splitext(filename)[0] + \".pdf\"\n",
      "            )\n",
      "            try:\n",
      "                print(f\"ğŸ”§ Converting {filename} â†’ {os.path.basename(pdf_path)} â€¦\")\n",
      "                convert(doc_path, pdf_path)\n",
      "            except Exception as e:\n",
      "                print(f\"âš ï¸ Failed to convert {filename}: {e}\")\n"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": 7,
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "text": [
        "ğŸ”„ Compressing mainayardaniel_127050_14924649_COGS 160 Le Corbusier Doc.pdf ...\n",
        "âœ… Saved compressed PDF: compressed_files/mainayardaniel_127050_14924649_COGS 160 Le Corbusier Doc.pdf\n"
       ]
      }
     ],
     "source": [
      "import os\n",
      "import fitz      # PyMuPDF\n",
      "from PIL import Image\n",
      "import io\n",
      "\n",
      "def compress_all_pdfs(input_dir, output_dir, dpi=100, downscale_factor=2):\n",
      "    \"\"\"\n",
      "    Compress all PDF files in `input_dir` by rendering each page to an image,\n",
      "    optionally downscaling, and reassembling into a new PDF in `output_dir`.\n",
      "    \"\"\"\n",
      "    os.makedirs(output_dir, exist_ok=True)\n",
      "    for filename in os.listdir(input_dir):\n",
      "        if not filename.lower().endswith(\".pdf\"):\n",
      "            continue\n",
      "        input_path = os.path.join(input_dir, filename)\n",
      "        output_path = os.path.join(output_dir, filename)\n",
      "        print(f\"ğŸ”„ Compressing {filename} ...\")\n",
      "        try:\n",
      "            doc = fitz.open(input_path)\n",
      "            new_pdf = fitz.open()\n",
      "            for page in doc:\n",
      "                pix = page.get_pixmap(dpi=dpi)\n",
      "                img = Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
      "                new_size = (pix.width // downscale_factor, pix.height // downscale_factor)\n",
      "                img = img.resize(new_size, Image.LANCZOS)\n",
      "                buffer = io.BytesIO()\n",
      "                img.save(buffer, format=\"PDF\", resolution=dpi)\n",
      "                buffer.seek(0)\n",
      "                img_pdf = fitz.open(\"pdf\", buffer)\n",
      "                new_pdf.insert_pdf(img_pdf)\n",
      "            new_pdf.save(output_path)\n",
      "            new_pdf.close()\n",
      "            doc.close()\n",
      "            print(f\"âœ… Saved compressed PDF: {output_path}\")\n",
      "        except Exception as e:\n",
      "            print(f\"âŒ Failed to compress {filename}: {e}\")\n"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": 13,
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "text": [
        "ğŸ” Unmatched login_ids: ['mainayardaniel' 'emralinolalaine' 'krukjulia' 'spavenchristine' 'khirwadkarisha' 'liangmichael' 'yangheiman' 'dasilvatheo' 'davidmatthew' 'marvanalicia' 'vidyalatanvi']\n",
        "\n",
        "âœ… Done! Check â†’ image_metadata_with_name_pid.csv\n"
       ]
      }
     ],
     "source": [
      "import pandas as pd\n",
      "from difflib import get_close_matches\n",
      "\n",
      "# â”€â”€ 1) Load CSVs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "meta_df   = pd.read_csv(\"image_metadata.csv\")\n",
      "roster_df = pd.read_csv(\"student_info.csv\")\n",
      "\n",
      "# â”€â”€ 2) Extract login_id from PDF filenames â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "meta_df[\"login_id\"] = meta_df[\"pdf_file\"].str.split(\"_\").str[0]\n",
      "\n",
      "# â”€â”€ 3) Tidy roster columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "roster_df = roster_df.rename(columns={\n",
      "    \"SIS Login ID\": \"login_id\",\n",
      "    \"Student\":      \"student_name\",\n",
      "    \"SIS User ID\":  \"pid\"\n",
      "})\n",
      "roster_df[\"student_name\"] = roster_df[\"student_name\"].fillna(\"\").astype(str).str.strip()\n",
      "\n",
      "# â”€â”€ 4) Exact-match merge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "merged = pd.merge(\n",
      "    meta_df,\n",
      "    roster_df[[\"login_id\",\"student_name\",\"pid\"]],\n",
      "    on=\"login_id\",\n",
      "    how=\"left\"\n",
      ")\n",
      "\n",
      "# â”€â”€ 5) Find unmatched IDs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "unmatched = merged.loc[merged[\"pid\"].isna(), \"login_id\"].unique()\n",
      "print(\"ğŸ” Unmatched login_ids:\", unmatched)\n",
      "\n",
      "# â”€â”€ 6) Prepare fuzzy matching â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "roster_df[\"norm_name\"] = (\n",
      "  roster_df[\"student_name\"].str.lower().str.replace(r\"[^a-z0-9]\", \"\", regex=True)\n",
      ")\n",
      "roster_map = { row.norm_name: (row.login_id, row.student_name, row.pid) for row in roster_df.itertuples() }\n",
      "\n",
      "# â”€â”€ 7) Fuzzy-match suggestions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "suggestions = {}\n",
      "for uid in unmatched:\n",
      "    key = str(uid).lower()\n",
      "    if key in roster_map:\n",
      "        suggestions[uid] = [roster_map[key]]\n",
      "        continue\n",
      "    hits = [roster_map[n] for n in roster_map if key in n or n in key]\n",
      "    if hits:\n",
      "        suggestions[uid] = hits\n",
      "        continue\n",
      "    best = get_close_matches(key, roster_map.keys(), n=1, cutoff=0.6)\n",
      "    suggestions[uid] = [roster_map[best[0]]] if best else []\n",
      "\n",
      "# â”€â”€ 8) Auto-fill unique matches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "for uid, matches in suggestions.items():\n",
      "    if len(matches) == 1:\n",
      "        _, name, pid = matches[0]\n",
      "        merged.loc[merged[\"login_id\"]==uid, \"student_name\"] = name\n",
      "        merged.loc[merged[\"login_id\"]==uid, \"pid\"]          = pid\n",
      "\n",
      "# â”€â”€ 9) Report ambiguous/no matches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "for uid, matches in suggestions.items():\n",
      "    if len(matches)>1:\n",
      "        print(f\"âš ï¸ {uid!r} HAS MULTIPLE MATCHES:\")\n",
      "        for _, name, pid in matches:\n",
      "            print(f\"    {name} â†’ {pid}\")\n",
      "    elif not matches:\n",
      "        print(f\"âŒ {uid!r} HAS NO CLOSE MATCH\")\n",
      "\n",
      "# â”€â”€10) Save result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "merged.to_csv(\"image_metadata_with_name_pid.csv\", index=False)\n",
      "print(\"âœ… Done! Check â†’ image_metadata_with_name_pid.csv\")\n"
     ]
    }
   ],
   "metadata": {
    "kernelspec": {
     "display_name": "XR_Lab (py3.11)",
     "language": "python",
     "name": "xr_lab_311"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "ipython",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.11.12"
    }
   },
   "nbformat": 4,
   "nbformat_minor": 2
  }
  